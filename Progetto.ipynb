{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP51GTJ9UFQo/y8PSXs4YHH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccsed/ProgettoLabAI/blob/main/Progetto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collego colab a google drive\n"
      ],
      "metadata": {
        "id": "dkejEQMvMXpr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WaJJRPjC6s4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107dc954-2447-40a1-8890-9a0203d37b51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importo le librerie necessarie"
      ],
      "metadata": {
        "id": "RLxBbaoYoljw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeK0MMwznpSr",
        "outputId": "dee86491-3873-4195-d999-57cbd197c1b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.10-cp310-cp310-manylinux2014_x86_64.whl (21.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.2.2)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.25.2)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.2)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.10 snuggs-1.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, datasets\n",
        "import albumentations as A\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import skimage.io as io\n",
        "from rasterio.plot import show\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms.functional as TF\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import torchvision\n",
        "from osgeo import gdal\n",
        "import cv2\n",
        "import tifffile as tiff\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import copy"
      ],
      "metadata": {
        "id": "BD5aG8Tloo4V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definisco alcune directory"
      ],
      "metadata": {
        "id": "lhMvQStro03e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive_dir = '/content/drive/MyDrive'\n",
        "image_dir = '/content/drive/MyDrive/Data/SN6_buildings_AOI_11_Rotterdam_train/train/AOI_11_Rotterdam/SAR-Intensity'\n",
        "train_path = '/content/drive/MyDrive/train.txt'\n",
        "val_path = '/content/drive/MyDrive/val.txt'\n",
        "test_path = '/content/drive/MyDrive/test.txt'"
      ],
      "metadata": {
        "id": "8Vk76qcKo8Jr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Media e std calcolate in Funzioni.ipynb"
      ],
      "metadata": {
        "id": "qah59_YjHGx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mean = [22.79312241, 24.30391245, 19.29892107, 17.69439361]\n",
        "# std = [16.42519281, 17.42876255, 14.27711349, 13.24714869]\n",
        "mean = [0.0, 0.0, 0.0, 0.0]\n",
        "std = [1.0, 1.0, 1.0, 1.0]"
      ],
      "metadata": {
        "id": "k_u4JlQmHKVA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definiamo la classe SARDataset"
      ],
      "metadata": {
        "id": "M0ytmvMccxNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class SARDataset(Dataset):\n",
        "#     def __init__(self, image_paths, mask_paths, transform=None):\n",
        "#         self.image_paths = image_paths\n",
        "#         self.mask_paths = mask_paths\n",
        "#         self.transform = transform\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.image_paths)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         image_path = self.image_paths[idx]\n",
        "#         mask_path = self.mask_paths[idx]\n",
        "\n",
        "\n",
        "#         with rasterio.open(image_path) as src:\n",
        "#             image = src.read().transpose((1, 2, 0))\n",
        "#             print(image.shape)\n",
        "#             image = image.astype(np.float32)\n",
        "\n",
        "#         with rasterio.open(mask_path) as src:\n",
        "#             mask = src.read(1)\n",
        "#             print(mask.shape)\n",
        "#             mask[mask == 255.0] = 1.0\n",
        "\n",
        "\n",
        "#         if self.transform is not None:\n",
        "#             augmentations = self.transform(image=image, mask=mask)\n",
        "#             image = augmentations[\"image\"]\n",
        "#             mask = augmentations[\"mask\"]\n",
        "\n",
        "#         return image, mask\n",
        "\n",
        "class SARDataset(Dataset):\n",
        "    def __init__(self, image_paths, mask_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        mask_path = self.mask_paths[idx]\n",
        "\n",
        "\n",
        "        image = tiff.imread(image_path)\n",
        "\n",
        "        mask = tiff.imread(mask_path)\n",
        "        if mask.ndim == 3:\n",
        "            mask = mask[:, :, 0]\n",
        "        mask = mask.astype(np.float32)\n",
        "        mask[mask == 255.0] = 1.0\n",
        "\n",
        "\n",
        "        if image.shape[:2] != mask.shape:\n",
        "            raise ValueError(f\"Le dimensioni dell'immagine {image_path} e della maschera {mask_path} non corrispondono.\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "            augmentations = self.transform(image=image, mask=mask)\n",
        "            image = augmentations[\"image\"]\n",
        "            mask = augmentations[\"mask\"]\n",
        "\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "RtvSgzHpc0Hk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carico i percorsi delle immagini per il training, il validation e il test set"
      ],
      "metadata": {
        "id": "IKLV-lrIdcmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(train_path, 'r') as f:\n",
        "    train_data = [line.split() for line in f.read().splitlines()]\n",
        "\n",
        "train_image_paths = [line[0] for line in train_data]\n",
        "train_label_paths = [line[1] for line in train_data]\n",
        "\n",
        "with open(val_path, 'r') as f:\n",
        "    val_data = [line.split() for line in f.read().splitlines()]\n",
        "\n",
        "val_image_paths = [line[0] for line in val_data]\n",
        "val_label_paths = [line[1] for line in val_data]\n",
        "\n",
        "with open(test_path, 'r') as f:\n",
        "    test_data = [line.split() for line in f.read().splitlines()]\n",
        "\n",
        "test_image_paths = [line[0] for line in test_data]\n",
        "test_label_paths = [line[1] for line in test_data]"
      ],
      "metadata": {
        "id": "CNdyy9f7dj8a"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creo il modello UNET"
      ],
      "metadata": {
        "id": "rRStPcN0OSoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classe DoubleConv"
      ],
      "metadata": {
        "id": "TtuN8w0ZPal7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(DoubleConv, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "wLkEzp6sOT8h"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classe UNET"
      ],
      "metadata": {
        "id": "U0cyDNFBPgsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNET(nn.Module):\n",
        "  def __init__(\n",
        "      self, in_channels=3, out_channels=1, features=[64, 128, 256, 512],\n",
        "  ):\n",
        "    super(UNET, self).__init__()\n",
        "    self.ups = nn.ModuleList()\n",
        "    self.downs = nn.ModuleList()\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    for feature in features:\n",
        "      self.downs.append(DoubleConv(in_channels, feature))\n",
        "      in_channels = feature\n",
        "\n",
        "    for feature in reversed(features):\n",
        "      self.ups.append(\n",
        "          nn.ConvTranspose2d(\n",
        "              feature*2, feature, kernel_size=2, stride=2,\n",
        "          )\n",
        "      )\n",
        "      self.ups.append(DoubleConv(feature*2, feature))\n",
        "\n",
        "    self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
        "    self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "  def forward(self, x):\n",
        "    skip_connections = []\n",
        "\n",
        "    for down in self.downs:\n",
        "      x = down(x)\n",
        "      skip_connections.append(x)\n",
        "      x = self.pool(x)\n",
        "\n",
        "    x = self.bottleneck(x)\n",
        "    skip_connections = skip_connections[::-1]\n",
        "\n",
        "    for idx in range(0, len(self.ups), 2):\n",
        "      x = self.ups[idx](x)\n",
        "      skip_connection = skip_connections[idx//2]\n",
        "\n",
        "      if x.shape != skip_connection.shape:\n",
        "        x = TF.resize(x, size=skip_connection.shape[2:])\n",
        "\n",
        "      concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "      x = self.ups[idx+1](concat_skip)\n",
        "\n",
        "    return self.final_conv(x)"
      ],
      "metadata": {
        "id": "3pD8M4goPi2_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "59my9iUsXpPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  x = torch.randn((3, 1, 160, 160))\n",
        "  model = UNET(in_channels=1, out_channels=1)\n",
        "  preds = model(x)\n",
        "  print(preds.shape)\n",
        "  print(x.shape)\n",
        "  assert preds.shape == x.shape\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  test()"
      ],
      "metadata": {
        "id": "LuF3NaBQXqWJ",
        "outputId": "db4e5421-3707-455c-caf3-93363d660aa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1, 160, 160])\n",
            "torch.Size([3, 1, 160, 160])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seed"
      ],
      "metadata": {
        "id": "JYtnwf5Mbyq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)"
      ],
      "metadata": {
        "id": "JFZtznP3bzr4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funzione per il training"
      ],
      "metadata": {
        "id": "a1BZxbOuo7ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
        "    loop = tqdm(loader)\n",
        "\n",
        "    for batch_idx, (data, targets) in enumerate(loop):\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.float().to(device=device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            predictions = model(data).squeeze(1)\n",
        "            loss = loss_fn(predictions, targets)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "# def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=30, device='cuda', accumulation_steps=4):\n",
        "#     best_f1 = 0.0\n",
        "\n",
        "#     scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "#     for epoch in range(num_epochs):\n",
        "#         for phase in ['train', 'val']:\n",
        "#             if phase == 'train':\n",
        "#                 model.train()\n",
        "#                 data_loader = train_loader\n",
        "#             else:\n",
        "#                 model.eval()\n",
        "#                 data_loader = val_loader\n",
        "\n",
        "#             running_loss = 0.0\n",
        "#             all_preds = []\n",
        "#             all_labels = []\n",
        "\n",
        "#             optimizer.zero_grad()\n",
        "\n",
        "#             for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f'{phase.capitalize()} Epoch {epoch+1}/{num_epochs}', leave=False)):\n",
        "#                 inputs = inputs.to(device)\n",
        "#                 labels = labels.to(device)\n",
        "\n",
        "#                 with torch.cuda.amp.autocast():\n",
        "#                     outputs = model(inputs).squeeze(1)\n",
        "#                     loss = criterion(outputs, labels) / accumulation_steps\n",
        "#                     preds = torch.sigmoid(outputs) > 0.5\n",
        "\n",
        "#                 if phase == 'train':\n",
        "#                     scaler.scale(loss).backward()\n",
        "\n",
        "#                     if (i + 1) % accumulation_steps == 0:\n",
        "#                         scaler.step(optimizer)\n",
        "#                         scaler.update()\n",
        "#                         optimizer.zero_grad()\n",
        "\n",
        "#                 running_loss += loss.item() * inputs.size(0) * accumulation_steps\n",
        "#                 all_preds.extend(preds.detach().cpu().numpy().flatten())\n",
        "#                 all_labels.extend(labels.detach().cpu().numpy().flatten())\n",
        "\n",
        "\n",
        "#             if phase == 'train' and (i + 1) % accumulation_steps != 0:\n",
        "#                 scaler.step(optimizer)\n",
        "#                 scaler.update()\n",
        "#                 optimizer.zero_grad()\n",
        "\n",
        "#             epoch_loss = running_loss / len(data_loader.dataset)\n",
        "\n",
        "#             if phase == 'train':\n",
        "#                 scheduler.step()\n",
        "#             else:\n",
        "#                 precision = precision_score(all_labels, all_preds)\n",
        "#                 recall = recall_score(all_labels, all_preds)\n",
        "#                 f1 = f1_score(all_labels, all_preds)\n",
        "#                 accuracy = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "#                 if f1 > best_f1:\n",
        "#                     best_f1 = f1\n",
        "#                     torch.save(model.state_dict(), \"/content/drive/MyDrive/best_model.pth\")\n",
        "\n",
        "#                 print(f\"Epoch {epoch+1}/{num_epochs} - {phase.capitalize()} Loss: {epoch_loss:.4f} Precision: {precision:.4f} Recall: {recall:.4f} F1: {f1:.4f} Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "dZjJbKsmo7DI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utils"
      ],
      "metadata": {
        "id": "mebla0LdshkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(state, filename=\"/content/drive/MyDrive/checkpoint.pth.tar\"):\n",
        "  print(\"=> Saving checkpoint\")\n",
        "  torch.save(state, filename)\n",
        "\n",
        "def load_checkpoint(checkpoint, model):\n",
        "  print(\"=> Loading checkpoint\")\n",
        "  model.load_state_dict(checkpoint[\"state_dict\"])"
      ],
      "metadata": {
        "id": "JwqGtaHAJ00f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy"
      ],
      "metadata": {
        "id": "L3KyIVO7OgJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(loader, model, loss_fn, device=\"cuda\"):\n",
        "  model.eval()\n",
        "  num_correct = 0\n",
        "  num_pixels = 0\n",
        "  dice_score = 0\n",
        "  precision = 0\n",
        "  recall = 0\n",
        "  f1 = 0\n",
        "  val_loss = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for x, y in loader:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device).unsqueeze(1)\n",
        "      preds = torch.sigmoid(model(x))\n",
        "      preds = (preds > 0.5).float()\n",
        "      num_correct += (preds == y).sum()\n",
        "      num_pixels += torch.numel(preds)\n",
        "      dice_score += (2 * (preds * y).sum()) / ((preds + y).sum() + 1e-8)\n",
        "      precision += precision_score(y.cpu().numpy().flatten(), preds.cpu().numpy().flatten())\n",
        "      recall += recall_score(y.cpu().numpy().flatten(), preds.cpu().numpy().flatten())\n",
        "      f1 += f1_score(y.cpu().numpy().flatten(), preds.cpu().numpy().flatten())\n",
        "      val_loss += loss_fn(preds, y).item()\n",
        "\n",
        "  val_loss /= len(loader)\n",
        "  print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "  print(f\"Accuracy: {num_correct/num_pixels*100:.2f}\")\n",
        "  print(f\"Dice score: {dice_score/len(loader)}\")\n",
        "  print(f\"Precision: {precision/len(loader)}\")\n",
        "  print(f\"Recall: {recall/len(loader)}\")\n",
        "  print(f\"F1 Score: {f1/len(loader)}\")\n",
        "\n",
        "  model.train()"
      ],
      "metadata": {
        "id": "n__fVZKKMaSj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_predictions_as_imgs(loader, model, folder, device=\"cuda\"):\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    model.eval()\n",
        "    for idx, (x, y) in enumerate(tqdm(loader, desc=\"Saving predictions\")):\n",
        "        x = x.to(device=device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = torch.sigmoid(model(x))\n",
        "            preds = (preds > 0.5).float()\n",
        "\n",
        "        for i in range(preds.shape[0]):\n",
        "            pred_tiff_path = os.path.join(folder, f\"pred_{idx * loader.batch_size + i}.png\")\n",
        "            tiff.imwrite(pred_tiff_path, preds[i].cpu().numpy().astype('float32'))\n",
        "\n",
        "\n",
        "        for i in range(y.shape[0]):\n",
        "            label_tiff_path = os.path.join(folder, f\"label_{idx * loader.batch_size + i}.png\")\n",
        "            tiff.imwrite(label_tiff_path, y[i].cpu().numpy().astype('float32'))\n",
        "\n",
        "    model.train()\n"
      ],
      "metadata": {
        "id": "sfPDFHfIOnET"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "\n",
        "transform = A.Compose([\n",
        "    A.Resize(height=128, width=128),\n",
        "    # A.HorizontalFlip(p=0.5),\n",
        "    # A.VerticalFlip(p=0.5),\n",
        "    # A.Rotate(limit=90, p=0.5),\n",
        "    A.Normalize(mean=mean, std=std),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "train_dataset = SARDataset(train_image_paths, train_label_paths, transform=transform)\n",
        "val_dataset = SARDataset(val_image_paths, val_label_paths, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
        "load_model = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNET(in_channels=4, out_channels=1).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "scheduler = StepLR(optimizer, step_size=9)\n",
        "num_epochs = 5\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "if load_model:\n",
        "  load_checkpoint(torch.load(\"/content/drive/MyDrive/checkpoint.pth.tar\"), model)\n",
        "\n"
      ],
      "metadata": {
        "id": "-V6po-gjQVEV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "        print(f\"epoch {epoch}\")\n",
        "        train_fn(train_loader, model, optimizer, criterion, scaler)\n",
        "\n",
        "        checkpoint = {\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"optimizer\": optimizer.state_dict(),\n",
        "        }\n",
        "        save_checkpoint(checkpoint)\n",
        "\n",
        "        check_accuracy(val_loader, model, criterion, device=device)\n",
        "\n",
        "        scheduler.step()"
      ],
      "metadata": {
        "id": "ptfFWcykRww3",
        "outputId": "636ba4c9-e052-41f8-a242-54b1d2f1aa8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/149 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "100%|██████████| 149/149 [12:05<00:00,  4.87s/it, loss=0.307]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Validation Loss: 0.6935\n",
            "Accuracy: 94.27\n",
            "Dice score: 0.012126022949814796\n",
            "Precision: 0.26289846031299946\n",
            "Recall: 0.006270886591758128\n",
            "F1 Score: 0.012126022426254941\n",
            "epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█▏        | 17/149 [05:01<38:59, 17.72s/it, loss=0.325]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1209aedd9ec7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch {epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         checkpoint = {\n",
            "\u001b[0;32m<ipython-input-16-c0e2a86f8e09>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(loader, model, optimizer, loss_fn, scaler)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}