{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeMP+A37p+wZDBoz7mmIdl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccsed/ProgettoLabAI/blob/main/Progetto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collego colab a google drive\n"
      ],
      "metadata": {
        "id": "dkejEQMvMXpr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WaJJRPjC6s4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e56bb920-6269-46c3-97fa-23cd0f3b6437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importo le librerie necessarie"
      ],
      "metadata": {
        "id": "RLxBbaoYoljw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeK0MMwznpSr",
        "outputId": "80516ff1-8f84-461a-be2d-9e2056bc19a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.10-cp310-cp310-manylinux2014_x86_64.whl (21.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.2.2)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.25.2)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.2)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.10 snuggs-1.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, datasets\n",
        "import albumentations as A\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import skimage.io as io\n",
        "from rasterio.plot import show\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms.functional as TF"
      ],
      "metadata": {
        "id": "BD5aG8Tloo4V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "gpu"
      ],
      "metadata": {
        "id": "-5XDgI6K9EqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "fxlXEV_s9GAo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definisco alcune directory"
      ],
      "metadata": {
        "id": "lhMvQStro03e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive_dir = '/content/drive/MyDrive'\n",
        "image_dir = '/content/drive/MyDrive/Data/SN6_buildings_AOI_11_Rotterdam_train/train/AOI_11_Rotterdam/SAR-Intensity'\n",
        "train_path = '/content/drive/MyDrive/train.txt'\n",
        "val_path = '/content/drive/MyDrive/val.txt'\n",
        "test_path = '/content/drive/MyDrive/test.txt'"
      ],
      "metadata": {
        "id": "8Vk76qcKo8Jr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Media e std calcolate in Funzioni.ipynb"
      ],
      "metadata": {
        "id": "qah59_YjHGx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = [1.92989217, 2.43039122, 2.27931228, 1.76943937]\n",
        "std = [1.50879955, 1.81904226, 1.72273382, 1.41520376]"
      ],
      "metadata": {
        "id": "k_u4JlQmHKVA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definisco le traformazioni"
      ],
      "metadata": {
        "id": "4UAg2pZqHz9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])"
      ],
      "metadata": {
        "id": "VRC9f077H2DX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definiamo la classe SARDataset"
      ],
      "metadata": {
        "id": "M0ytmvMccxNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SARDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = self.load_image(image_path)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "    def load_image(self, image_path):\n",
        "        with rasterio.open(image_path) as src:\n",
        "            image = src.read()\n",
        "            image = image.astype('float32')\n",
        "            image = np.transpose(image, (1, 2, 0))\n",
        "        return image"
      ],
      "metadata": {
        "id": "RtvSgzHpc0Hk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carico i percorsi delle immagini per il training, il validation e il test set"
      ],
      "metadata": {
        "id": "IKLV-lrIdcmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(train_path, 'r') as f:\n",
        "    train_data = [line.split() for line in f.read().splitlines()]\n",
        "\n",
        "train_image_paths = [line[0] for line in train_data]\n",
        "\n",
        "with open(val_path, 'r') as f:\n",
        "    val_data = [line.split() for line in f.read().splitlines()]\n",
        "\n",
        "val_image_paths = [line[0] for line in val_data]\n",
        "\n",
        "with open(test_path, 'r') as f:\n",
        "    test_data = [line.split() for line in f.read().splitlines()]\n",
        "\n",
        "test_image_paths = [line[0] for line in test_data]"
      ],
      "metadata": {
        "id": "CNdyy9f7dj8a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creo il dataset"
      ],
      "metadata": {
        "id": "mvgLA_9Ui7_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SARDataset(train_image_paths, transform=transform)\n",
        "val_dataset = SARDataset(val_image_paths, transform=transform)\n",
        "test_dataset = SARDataset(test_image_paths, transform=transform)"
      ],
      "metadata": {
        "id": "so6w40wKi9xu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creo i DataLoader"
      ],
      "metadata": {
        "id": "T5-O-Ax9kBOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=1)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32,  shuffle=False, num_workers=1)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=1)"
      ],
      "metadata": {
        "id": "KoV-t7cRkCgo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for batch in train_loader:\n",
        "#     print(\"Dimensioni del batch di input:\", batch.shape)\n",
        "#     break"
      ],
      "metadata": {
        "id": "x_wM52IZ634a"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creo il modello UNET"
      ],
      "metadata": {
        "id": "rRStPcN0OSoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classe DoubleConv"
      ],
      "metadata": {
        "id": "TtuN8w0ZPal7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(DoubleConv, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "wLkEzp6sOT8h"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classe UNET"
      ],
      "metadata": {
        "id": "U0cyDNFBPgsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNET(nn.Module):\n",
        "  def __init__(\n",
        "      self, in_channels=4, out_channels=1, features=[64, 128, 256, 512],\n",
        "  ):\n",
        "    super(UNET, self).__init__()\n",
        "    self.ups = nn.ModuleList()\n",
        "    self.downs = nn.ModuleList()\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    for feature in features:\n",
        "      self.downs.append(DoubleConv(in_channels, feature))\n",
        "      in_channels = feature\n",
        "\n",
        "    for feature in reversed(features):\n",
        "      self.ups.append(\n",
        "          nn.ConvTranspose2d(\n",
        "              feature*2, feature, kernel_size=2, stride=2,\n",
        "          )\n",
        "      )\n",
        "      self.ups.append(DoubleConv(feature*2, feature))\n",
        "\n",
        "    self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
        "    self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "  def forward(self, x):\n",
        "    skip_connections = []\n",
        "\n",
        "    for down in self.downs:\n",
        "      x = down(x)\n",
        "      skip_connections.append(x)\n",
        "      x = self.pool(x)\n",
        "\n",
        "    x = self.bottleneck(x)\n",
        "    skip_connections = skip_connections[::-1]\n",
        "\n",
        "    for idx in range(0, len(self.ups), 2):\n",
        "      x = self.ups[idx](x)\n",
        "      skip_connection = skip_connections[idx//2]\n",
        "\n",
        "      if x.shape != skip_connection.shape:\n",
        "        x = TF.resize(x, size=skip_connection.shape[2:])\n",
        "\n",
        "      concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "      x = self.ups[idx+1](concat_skip)\n",
        "\n",
        "    return self.final_conv(x)"
      ],
      "metadata": {
        "id": "3pD8M4goPi2_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "59my9iUsXpPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  x = torch.randn((3, 1, 160, 160))\n",
        "  model = UNET(in_channels=1, out_channels=1)\n",
        "  preds = model(x)\n",
        "  print(preds.shape)\n",
        "  print(x.shape)\n",
        "  assert preds.shape == x.shape\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  test()"
      ],
      "metadata": {
        "id": "LuF3NaBQXqWJ",
        "outputId": "f6528816-8f9c-45de-8321-d2458a666e94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1, 160, 160])\n",
            "torch.Size([3, 1, 160, 160])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "min 23:38"
      ],
      "metadata": {
        "id": "g9P1aDwhZmEl"
      }
    }
  ]
}