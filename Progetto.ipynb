{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOKBRcpR1mKDKi4VPaxWdHZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccsed/ProgettoLabAI/blob/main/Progetto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collego colab a google drive\n"
      ],
      "metadata": {
        "id": "dkejEQMvMXpr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WaJJRPjC6s4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b456e91d-ccba-44d9-8387-34fcb0d97eb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importo le librerie necessarie"
      ],
      "metadata": {
        "id": "RLxBbaoYoljw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeK0MMwznpSr",
        "outputId": "8202a024-8732-4913-9c20-8fa3fc93fad6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.10-cp310-cp310-manylinux2014_x86_64.whl (21.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.2.2)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.25.2)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.2)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.10 snuggs-1.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, datasets\n",
        "import albumentations as A\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import skimage.io as io\n",
        "from rasterio.plot import show\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms.functional as TF\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "BD5aG8Tloo4V"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "gpu"
      ],
      "metadata": {
        "id": "-5XDgI6K9EqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "fxlXEV_s9GAo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definisco alcune directory"
      ],
      "metadata": {
        "id": "lhMvQStro03e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive_dir = '/content/drive/MyDrive'\n",
        "image_dir = '/content/drive/MyDrive/Data/SN6_buildings_AOI_11_Rotterdam_train/train/AOI_11_Rotterdam/SAR-Intensity'\n",
        "train_path = '/content/drive/MyDrive/train.txt'\n",
        "val_path = '/content/drive/MyDrive/val.txt'\n",
        "test_path = '/content/drive/MyDrive/test.txt'"
      ],
      "metadata": {
        "id": "8Vk76qcKo8Jr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Media e std calcolate in Funzioni.ipynb"
      ],
      "metadata": {
        "id": "qah59_YjHGx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = [22.79312241, 24.30391245, 19.29892107, 17.69439361]\n",
        "std = [16.42519281, 17.42876255, 14.27711349, 13.24714869]"
      ],
      "metadata": {
        "id": "k_u4JlQmHKVA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definisco le traformazioni"
      ],
      "metadata": {
        "id": "4UAg2pZqHz9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])"
      ],
      "metadata": {
        "id": "VRC9f077H2DX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definiamo la classe SARDataset"
      ],
      "metadata": {
        "id": "M0ytmvMccxNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SARDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.images = os.listdir(image_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.image_dir, self.images[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.images[idx].replace(\".jpg\" \".tif\"))\n",
        "        image = np.array(Image.open(image_path).convert(\"RGB\"))\n",
        "        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\n",
        "        mask[mask == 255.0] = 1.0\n",
        "\n",
        "        if self.transform is not None:\n",
        "          augmentations = self.transform(image=image, mask=mask)\n",
        "          image = augmentations[\"image\"]\n",
        "          mask = augmentations[\"mask\"]\n",
        "\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "RtvSgzHpc0Hk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carico i percorsi delle immagini per il training, il validation e il test set"
      ],
      "metadata": {
        "id": "IKLV-lrIdcmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(train_path, 'r') as f:\n",
        "    train_data = [line.split() for line in f.read().splitlines()]\n",
        "\n",
        "train_image_paths = [line[0] for line in train_data]\n",
        "train_label_paths = [line[1] for line in train_data]\n",
        "\n",
        "with open(val_path, 'r') as f:\n",
        "    val_data = [line.split() for line in f.read().splitlines()]\n",
        "\n",
        "val_image_paths = [line[0] for line in val_data]\n",
        "val_label_paths = [line[1] for line in val_data]\n",
        "\n",
        "with open(test_path, 'r') as f:\n",
        "    test_data = [line.split() for line in f.read().splitlines()]\n",
        "\n",
        "test_image_paths = [line[0] for line in test_data]\n",
        "test_label_paths = [line[1] for line in test_data]"
      ],
      "metadata": {
        "id": "CNdyy9f7dj8a"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creo il modello UNET"
      ],
      "metadata": {
        "id": "rRStPcN0OSoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classe DoubleConv"
      ],
      "metadata": {
        "id": "TtuN8w0ZPal7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(DoubleConv, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "wLkEzp6sOT8h"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classe UNET"
      ],
      "metadata": {
        "id": "U0cyDNFBPgsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNET(nn.Module):\n",
        "  def __init__(\n",
        "      self, in_channels=4, out_channels=1, features=[64, 128, 256, 512],\n",
        "  ):\n",
        "    super(UNET, self).__init__()\n",
        "    self.ups = nn.ModuleList()\n",
        "    self.downs = nn.ModuleList()\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    for feature in features:\n",
        "      self.downs.append(DoubleConv(in_channels, feature))\n",
        "      in_channels = feature\n",
        "\n",
        "    for feature in reversed(features):\n",
        "      self.ups.append(\n",
        "          nn.ConvTranspose2d(\n",
        "              feature*2, feature, kernel_size=2, stride=2,\n",
        "          )\n",
        "      )\n",
        "      self.ups.append(DoubleConv(feature*2, feature))\n",
        "\n",
        "    self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
        "    self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "  def forward(self, x):\n",
        "    skip_connections = []\n",
        "\n",
        "    for down in self.downs:\n",
        "      x = down(x)\n",
        "      skip_connections.append(x)\n",
        "      x = self.pool(x)\n",
        "\n",
        "    x = self.bottleneck(x)\n",
        "    skip_connections = skip_connections[::-1]\n",
        "\n",
        "    for idx in range(0, len(self.ups), 2):\n",
        "      x = self.ups[idx](x)\n",
        "      skip_connection = skip_connections[idx//2]\n",
        "\n",
        "      if x.shape != skip_connection.shape:\n",
        "        x = TF.resize(x, size=skip_connection.shape[2:])\n",
        "\n",
        "      concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "      x = self.ups[idx+1](concat_skip)\n",
        "\n",
        "    return self.final_conv(x)"
      ],
      "metadata": {
        "id": "3pD8M4goPi2_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "59my9iUsXpPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  x = torch.randn((3, 1, 160, 160))\n",
        "  model = UNET(in_channels=1, out_channels=1)\n",
        "  preds = model(x)\n",
        "  print(preds.shape)\n",
        "  print(x.shape)\n",
        "  assert preds.shape == x.shape\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  test()"
      ],
      "metadata": {
        "id": "LuF3NaBQXqWJ",
        "outputId": "f2f93c4b-3ff0-479e-e45f-c91a748a573c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1, 160, 160])\n",
            "torch.Size([3, 1, 160, 160])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definisco costanti per il training"
      ],
      "metadata": {
        "id": "g9P1aDwhZmEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-4\n",
        "batch_size = 16\n",
        "num_epochs = 30\n",
        "num_workers = 2\n",
        "image_height = 900\n",
        "image_width = 900\n",
        "pin_memory = True\n",
        "load_model = False"
      ],
      "metadata": {
        "id": "EZD39UDKoIwD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funzione per il training"
      ],
      "metadata": {
        "id": "a1BZxbOuo7ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
        "  loop = tqdm(loader)\n",
        "\n",
        "  for batch_idx, (data, targets) in enumerate(loop):\n",
        "    data = data.to(device=device)\n",
        "    targets = targets.float().unsqueeze(1).to(device=device)\n",
        "\n",
        "    with torch.cuda.amp.autocast():\n",
        "      predictions = model(data)\n",
        "      loss = loss_fn(predictions, targets)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    scaler.scale(loss).backward()\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "\n",
        "    loop.set_postfix(loss=loss.item())"
      ],
      "metadata": {
        "id": "dZjJbKsmo7DI"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funzione main"
      ],
      "metadata": {
        "id": "_Ktla1b2pEb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    train_transforms = A.Compose(\n",
        "        [\n",
        "            A.RandomRotate90(p = 1.0),\n",
        "            A.HorizontalFlip(p = 0.5),\n",
        "            A.VerticalFlip(p = 0.5),\n",
        "            A.Normalize(mean=mean, std=std),\n",
        "            ToTensorV2(),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    model = UNET(in_channels=3, out_channels=1).to(device)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    train_loader, val_loader = get_loaders(\n",
        "        train_image_paths,\n",
        "        train_label_paths,\n",
        "        val_image_paths,\n",
        "        val_label_paths,\n",
        "        batch_size,\n",
        "        train_transforms,\n",
        "        train_transforms\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "id": "Ra-9EDrdpGch"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}